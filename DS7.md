#### Создать инстанс ВМ с 2 ядрами и 4 Гб ОЗУ и SSD 10GB
#### Установить на него PostgreSQL 15 с дефолтными настройками
#### Создать БД для тестов: выполнить pgbench -i postgres
#### Запустить pgbench -c8 -P 6 -T 60 -U postgres postgres
```sql
postgres@Ubuntu:~$  pgbench -c8 -P 6 -T 60 -U postgres postgres
starting vacuum...end.
progress: 6.0 s, 1078.5 tps, lat 7.388 ms stddev 6.324
progress: 12.0 s, 1176.3 tps, lat 6.794 ms stddev 5.828
progress: 18.0 s, 1150.5 tps, lat 6.947 ms stddev 6.120
progress: 24.0 s, 990.5 tps, lat 8.074 ms stddev 7.330
progress: 30.0 s, 1067.3 tps, lat 7.496 ms stddev 6.449
progress: 36.0 s, 1153.7 tps, lat 6.927 ms stddev 6.026
progress: 42.0 s, 1077.7 tps, lat 7.416 ms stddev 6.435
progress: 48.0 s, 1137.7 tps, lat 7.029 ms stddev 6.332
progress: 54.0 s, 1102.7 tps, lat 7.246 ms stddev 6.299
progress: 60.0 s, 1191.9 tps, lat 6.710 ms stddev 5.748
transaction type: <builtin: TPC-B (sort of)>
scaling factor: 1
query mode: simple
number of clients: 8
number of threads: 1
duration: 60 s
number of transactions actually processed: 66768
latency average = 7.183 ms
latency stddev = 6.293 ms
tps = 1112.534045 (including connections establishing)
tps = 1112.567822 (excluding connections establishing)
```
#### Применить параметры настройки PostgreSQL из прикрепленного к материалам занятия файла
#### Протестировать заново
```sql
postgres@Ubuntu:~$  pgbench -c8 -P 6 -T 60 -U postgres postgres
starting vacuum...end.
progress: 6.0 s, 1192.8 tps, lat 6.669 ms stddev 5.460
progress: 12.0 s, 1234.3 tps, lat 6.475 ms stddev 5.247
progress: 18.0 s, 1253.5 tps, lat 6.375 ms stddev 5.365
progress: 24.0 s, 1262.3 tps, lat 6.335 ms stddev 5.695
progress: 30.0 s, 1248.0 tps, lat 6.407 ms stddev 5.540
progress: 36.0 s, 1243.5 tps, lat 6.431 ms stddev 5.590
progress: 42.0 s, 1262.2 tps, lat 6.332 ms stddev 5.322
progress: 48.0 s, 1245.0 tps, lat 6.419 ms stddev 5.377
progress: 54.0 s, 1256.9 tps, lat 6.361 ms stddev 5.307
progress: 60.0 s, 1246.8 tps, lat 6.412 ms stddev 5.371
transaction type: <builtin: TPC-B (sort of)>
scaling factor: 1
query mode: simple
number of clients: 8
number of threads: 1
duration: 60 s
number of transactions actually processed: 74680
latency average = 6.422 ms
latency stddev = 5.435 ms
tps = 1243.971498 (including connections establishing)
tps = 1244.034881 (excluding connections establishing)
```
#### Что изменилось и почему?
#### Результаты улучшились. TPS возрос на 11%
* мы увеличили ___shared_buffers___ и сделали его 25% от общей памяти. Параметр shared_buffers определяет объем памяти, выделенной серверу для кэширования данных. По ДЗ RAM=4G. Мы установили 1G, что соответствует рекомендациям. 
* Уменьшили параметр ___effective_cache_size___ с 4G до 3G. Он оценивает, сколько памяти доступно для кэширования диска ОС и в самой базе данных. Планировщик запросов Postgresql решает, зафиксировано ли это в оперативной памяти или нет.Вообщем этот параметр сообщает Postgresql, сколько памяти доступно для кэширования его файлов. Если значение высокое, то Potgresql будет оценивать соединения вложенных циклов с индексным сканированием дешевле, поскольку он предполагает, что индекс скорее всего будет кэширован. Сканирование индекса, скорее всего будет использоваться для более высоких значений, в противном случая, если значение низкое, будет использоваться последовательное сканирование. Рекомендуется устанавливать effective_cache_size на уровне 50% от общего объема оперативной памяти машины. По заданию ДЗ ОЗУ=4G. Мы поставили 3G, хотя по рекомендации надо было ставить 2G.
* ___maintenance_work_mem___ установили 512MB. т.е. увеличили с 64MB. Этот параметр по сути определяет максимальный объем памяти, который будет использоваться операциями обслуживания. Что-бы рассчитать подходящее значение, можно воспользоваться следующей формулой ( по рекомендации AWS) maintenance_work_mem=(total_memory-shared_buffers)/(max_connection\*5)=(4-1)/(40\*5)=15MB. Чем больше памяти, тем большее значение можно выбрать, и чем больше количество подключений, тем меньше можно брать maintenance_work_mem , потому что при запуске автовакуума эта память может быть выделена до autovacuum_max_workers раз, поэтому слишком большое значение не рекомендуется устанавливать. Можно этот процесс так же контролировать, отдельно устанавливая autovacuum_work_mem. Но только одна из операций VACUUM, CREATE INDEX, ALTER TABLE, ADD FOREIGN KEY может быть выполнена сеансом базы данных за раз , а обычно не выполняется много из них одновременно, то можно безопасно установить это значение значительно больше work_mem. Большие настройки могут улучшить производительность очистки и восстановления БД. Поэтому, выставляем это значение в зависимости от контекста. Мы, соответственно увеличили этот параметр.
* ___checkpoint_completion_target___, по заданию равен 0.9. Этот параметр указывает цель завершения контрольной точки, как долю от общего времени между контрольными точками. Значение по умолчанию 0.9, что распределяет контрольную точку почти по всему дотупному интервалу, обеспечивая довольно постоянную нагрузку ввода-вывода, а так же оставляет некоторое время для накладных расходов на завершение контрольной точки. Уменьшать этот параметр не рекомендуется, поскольку приведет к более быстрому завершению КТ. А это, в свою очередь приведет к более высокой скорости ввода-вывода во время КТ, за которой следует период меньшего ввода-вывода между завершением КТ и следующей запланированной. контрольной точкой. Этот параметр установлен так как нужно, поэтому его не меняли.
* ___wal_buffers___ , по заданию равен 16MB. Этот параметр указывает объем разделяемой памяти, используемый для данных WAL, которые еще не были записаны на диск. Значение по умолчанию -1, и это значит, что БД сделает размер равный 1/32(около 3%) от shared_buffers, но не меньше 64KB и не больше размера одного сегмента WAL/ Обычно 16MB. Но у нас shared_buffers=1G, следовательно, если параметр будет -1, то для wal_buffers будет выделено 32MB. Но мы его уменьшили до 16MB. Содержимое буферов wal записывается на диск при каждом подтверждении транзакции, поэтому слишком большие значения вряд ли дадут существенную выгоду. Однако, установка этого значения небольшим может повысить производительность записи на загруженном сервере, где много клиентов подтверждают транзакции одновременно.
* ___default_statistics_target___ , значение по умолчанию 100. Большинство приложений могут использовать значение по умолчанию 100. Для маленьких или простых БД можно этот параметр уменьшить до 10 или 50. Приложениям хранилищ данных обычно требуется значение от 500 до 1000. Мы выставили 500 Это ближе к приложениям хранилищ данных. Эта настройка определяет, сколько информации Postgresql собирает из нашей таблицы, чтобы затем принимать решения по планированию. Если этот показатель 100 , то это означает, что соберется выборка из 30000 строк. По сути это количество образцов, которое мы собираем.
* ___random_page_cost___, мы оставляем по умолчанию 4. Этот параметр устанавливает оценку планировщиком стоимости непоследовательно извлеченной страницы диска. Уменьшение этого параметра относительно seq_page_cost приведет к тому, что система будет отдавать предпочтение индексному сканированию, его увеличение сделает индексное сканирование относительно более дорогим. Случайный доступ к механическому дисковому хранилищу обычно намного дороже, чем в четыре раза последовательный доступ.
* ___effective_io_concurrency___ отражает количество одновременных запросов, которые могут быть эффективно обработаны дисковой подсистемой. Увеличение этого значения увеличит количество операций ввода-вывода, которые любой отдельный сеанс Postgresql инициировать параллельно. Допустимый диапазон от 1 до 1000 или 0, что бы отключить выдачу асинхронных запросов ввода вывода. В настоящее время этот параметр влияет только на сканирование кучи bitmap. Для магнитных дисков хорошей отправной точкой для этого параметра является количество отдельных дисков, составляющих R0 или зеркало R1, используемое для БД. SSD и другие хранилища на основе памяти часто могут обрабатывать много параллельных запросов, поэтому оптимальным значением может быть несколько сотен. Мы выставили этот параметр для HDD, хотя у меня SSD
* ___work_mem___ устанавливает максимальный объем памяти, который будет использоваться для операций запроса перед записью во временные файлы. В ДЗ 6553kB. Значение по умолчанию 4MB. Сложный запрос может выполнять несколько операций сортировки и хэширования одновременно при этом каждой операции обычно разрешено использовать столько памяти, сколько указано в этом значении, прежде чем она начнет записывать во временные файлы, кроме того, несколько запущенных сеансов могут выполнять такие операции одновременно. Операции сортировки используются для ORDER BY, DISTINCT, MERGE JOINS. Хэш-таблицы используются в хэш соединениях , агрегации на основе хэша, узлах memoize и обработке подзапросов на основе хэша IN.. Операции на основе хэша обычно более чувствительны к доступности памяти, чем эквивалентные операции на основе сортировки. Предел памяти для хэш-таблицы вычисляется путем умножения work_mem*hash_mem_multiplier(по умолчанию 2.0). Именно этот факт позволяет операциям на основе хэша использовать объем памяти, превышающий обычный базовый объем work_mem. Поэтому общий обьем используемой памяти может во много раз превышать значение work_mem. Так же можно использовать формулу work_mem=(instatce_memory*0.8-shared_buffers)/active_connection_count. По это формуле выходит 5MB
* ___min(max)_wal_size___ количество файлов сегментов WAL в pg_wal каталоге, сгенерированного в предыдущих циклах контрольных точек. Когда старые файлы сегментов WAL больше не нужны, они удаляются или перерабатываются(то есть переименовываются, что бы стать будущими сегментамив пронумерованной последовательности). Если из-за кратковременного пика скорости вывода WAL max_wal_size превышено, ненужные файлы будут удаляться, пока система не вернется в пределы своего лимита. Мы выставили 4GB и 16GB для случая, если у нас Data WareHouse нагрузка.
* 
#### Создать таблицу с текстовым полем и заполнить случайными или сгенерированными данным в размере 1млн строк
```sql
postgres=# create table t2 (n text);
CREATE TABLE
postgres=# select count(*) from test_vacuum ;
  count  
---------
 1000001
(1 row)
postgres=# select * from test_vacuum limit 4 ;
               t               
-------------------------------
 Skye.Jacobson@hotmail.com
 Malinda.Hagenes42@hotmail.com
 Hank.Rath75@gmail.com
 Logan_Emard@hotmail.com
(4 rows)
```
#### Посмотреть размер файла с таблицей
```bash
postgres=# select pg_relation_filepath('test_vacuum');
 pg_relation_filepath 
----------------------
 base/13465/222417
(1 row)

postgres@Ubuntu:~/12/main/base/13465$ du -h 222417
54M	222417
```
#### 5 раз обновить все строчки и добавить к каждой строчке любой символ
```sql
postgres=# update test_vacuum set t=t ||'!';
UPDATE 1000001
postgres=# select * from test_vacuum limit 4 ;
             t             
---------------------------
 Nelda2@hotmail.com!!!!!!
 Vicenta18@gmail.com!!!!!!
 Bart4@yahoo.com!!!!!!
 Nathen35@gmail.com!!!!!!
(4 rows)

```
#### Посмотреть количество мертвых строчек в таблице и когда последний раз приходил автовакуум
```sql
если обновить пять раз
postgres=# SELECT relname, n_live_tup, n_dead_tup, trunc(100*n_dead_tup/(n_live_tup+1))::float "ratio%", last_autovacuum FROM pg_stat_user_tables WHERE relname = 'test_vacuum';
   relname   | n_live_tup | n_dead_tup | ratio% |        last_autovacuum        
-------------+------------+------------+--------+-------------------------------
 test_vacuum |    1000001 |    4997467 |    499 | 2025-02-13 11:42:47.153071+03
(1 row)
если обновить один раз
postgres=# SELECT relname, n_live_tup, n_dead_tup, trunc(100*n_dead_tup/(n_live_tup+1))::float "ratio%", last_autovacuum FROM pg_stat_user_tables WHERE relname = 'test_vacuum';
   relname   | n_live_tup | n_dead_tup | ratio% |        last_autovacuum        
-------------+------------+------------+--------+-------------------------------
 test_vacuum |    1000001 |    1000001 |     99 | 2025-02-13 11:46:49.091624+03
(1 row)

```
* Количество мертвых строк увеличилось в пять раз, потому что мы пять раз обновили всю таблицу
* Соответственно количество мертвых строк увеличилось в два раза, т.к. мы один раз обновили каждую строку таблицы, и автовакуум не успел еще почистить таблицу
#### Подождать некоторое время, проверяя, пришел ли автовакуум
```sql
postgres=# SELECT relname, n_live_tup, n_dead_tup, trunc(100*n_dead_tup/(n_live_tup+1))::float "ratio%", last_autovacuum FROM pg_stat_user_tables WHERE relname = 'test_vacuum';
   relname   | n_live_tup | n_dead_tup | ratio% |        last_autovacuum        
-------------+------------+------------+--------+-------------------------------
 test_vacuum |    1000001 |          0 |      0 | 2025-02-13 11:47:48.609629+03
(1 row)
```
#### 5 раз обновить все строчки и добавить к каждой строчке любой символ
#### Посмотреть размер файла с таблицей
```sql
postgres@Ubuntu:~/12/main/base/13465$ du -h 222417
340M	222417
```
#### Отключить Автовакуум на конкретной таблице
```sql
postgres=# alter table test_vacuum set (autovacuum_enabled = off);
ALTER TABLE
```
#### 10 раз обновить все строчки и добавить к каждой строчке любой символ
```sql
postgres=# update test_vacuum set t=t ||'!';
UPDATE 1000001
postgres=# update test_vacuum set t=t ||'!';
UPDATE 1000001
postgres=# update test_vacuum set t=t ||'!';
UPDATE 1000001
postgres=# update test_vacuum set t=t ||'!';
UPDATE 1000001
postgres=# update test_vacuum set t=t ||'!';
UPDATE 1000001
postgres=# update test_vacuum set t=t ||'!';
UPDATE 1000001
postgres=# update test_vacuum set t=t ||'!';
UPDATE 1000001
postgres=# update test_vacuum set t=t ||'!';
UPDATE 1000001
postgres=# update test_vacuum set t=t ||'!';
UPDATE 1000001
postgres=# update test_vacuum set t=t ||'!';
UPDATE 1000001
```

#### Посмотреть размер файла с таблицей
```sql
postgres@Ubuntu:~/12/main/base/13465$ du -h 222417
710M	222417
```
#### Объясните полученный результат
* Файл с таблицей увеличился, т.к. был отключен автовакуум, и таблица разбухла. 
#### Написать анонимную процедуру, в которой в цикле 10 раз обновятся все строчки в искомой таблице.

```sql
DO 
$$DECLARE x numeric=1;
BEGIN 
    FOR i IN 1..10 LOOP
            update test_vacuum set t=t ||'$';
			x=x+1;
			END LOOP;	
	END;
$$ LANGUAGE plpgsql;

```
